#!/usr/bin/env -S uv run python3
"""
Haiku LLM CLI Tool - Komposition Generator
Generates video komposition JSON from natural language descriptions
"""
import argparse
import json
import sys
import time
import asyncio
from pathlib import Path

# Add lib directory to path for API client
sys.path.insert(0, str(Path(__file__).parent.parent / "lib"))

try:
    from haiku_api_client import haiku_client, HaikuResponse
    from sonnet_validator import validate_with_sonnet, ValidationResult
    API_AVAILABLE = True
    SONNET_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Haiku API client not available: {e}")
    print("Falling back to simulation mode")
    API_AVAILABLE = False
    SONNET_AVAILABLE = False

async def call_haiku_llm_api(prompt, bmp=120, confidence_threshold=0.8) -> dict:
    """
    Real Haiku API call for komposition generation
    """
    system_prompt = """You are a video komposition expert. Generate valid JSON kompositions from natural language descriptions.

Focus on:
- Precise BPM timing calculations
- Segment structure with beat alignment  
- Effect parameters based on style descriptions
- Audio integration settings

Return only valid JSON in this format:
{
  "metadata": {
    "title": "string",
    "bpm": number,
    "estimatedDuration": number,
    "created": "ISO datetime",
    "generated_by": "haiku-llm"
  },
  "segments": [
    {
      "id": "string",
      "startBeat": number,
      "durationBeats": number, 
      "startTime": number,
      "duration": number,
      "effects": []
    }
  ],
  "audio": {
    "backgroundMusic": "string",
    "volume": number
  }
}"""
    
    try:
        async with haiku_client() as client:
            response = await client.call_haiku(prompt, system_prompt, confidence_threshold)
            
            if response.success:
                try:
                    # Parse JSON response
                    komposition = json.loads(response.content)
                    
                    return {
                        "success": True,
                        "komposition": komposition,
                        "confidence": response.confidence,
                        "processing_time": response.processing_time,
                        "cost_usd": response.cost_usd,
                        "escalation_needed": response.escalation_needed
                    }
                except json.JSONDecodeError as e:
                    return {
                        "success": False,
                        "error": f"Invalid JSON response: {e}",
                        "confidence": 0.0,
                        "processing_time": response.processing_time,
                        "cost_usd": response.cost_usd,
                        "escalation_needed": True,
                        "raw_content": response.content
                    }
            else:
                return {
                    "success": False,
                    "error": response.error,
                    "confidence": 0.0,
                    "processing_time": response.processing_time,
                    "cost_usd": response.cost_usd,
                    "escalation_needed": True
                }
                
    except Exception as e:
        return {
            "success": False,
            "error": f"API call failed: {e}",
            "confidence": 0.0,
            "processing_time": 0.0,
            "cost_usd": 0.0,
            "escalation_needed": True
        }

def simulate_haiku_llm_call(prompt, bpm=120, confidence_threshold=0.8):
    """
    Simulates Haiku LLM API call for komposition generation
    In real implementation, this would call Anthropic's Haiku API
    """
    # Simulate processing time (Haiku is fast!)
    time.sleep(0.5)
    
    # Extract key information from prompt for simulation
    segments = 12 if "12 segments" in prompt else 4
    beats_per_segment = 4 if "4 beats" in prompt else 8
    
    # Generate sample komposition JSON
    komposition = {
        "metadata": {
            "title": "Generated Music Video",
            "bpm": bpm,
            "estimatedDuration": (segments * beats_per_segment * 60) / bpm,
            "created": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
            "generated_by": "haiku-llm",
            "source_prompt": prompt
        },
        "segments": []
    }
    
    # Generate segments based on prompt analysis
    for i in range(segments):
        segment = {
            "id": f"segment_{i+1:02d}",
            "startBeat": i * beats_per_segment,
            "durationBeats": beats_per_segment,
            "startTime": (i * beats_per_segment * 60) / bpm,
            "duration": (beats_per_segment * 60) / bpm,
            "effects": []
        }
        
        # Add effects based on prompt keywords
        if "old school" in prompt.lower():
            segment["effects"].append({
                "type": "vintage_color",
                "parameters": {
                    "warmth": 1.3,
                    "saturation": 0.75,
                    "grain": 0.4
                }
            })
        
        if "fade to white" in prompt.lower():
            segment["effects"].append({
                "type": "fade_white_out",
                "parameters": {
                    "duration": 0.5
                }
            })
            
        komposition["segments"].append(segment)
    
    # Add audio configuration
    if "wav" in prompt.lower() or "audio" in prompt.lower():
        komposition["audio"] = {
            "backgroundMusic": "extracted_from_prompt",
            "volume": 0.8,
            "fadeIn": 1.0,
            "fadeOut": 2.0
        }
    
    # Simulate confidence scoring
    keyword_matches = sum([
        1 for keyword in ["bpm", "segments", "beats", "music", "video"]
        if keyword in prompt.lower()
    ])
    confidence = min(0.95, 0.6 + (keyword_matches * 0.1))
    
    return {
        "success": True,
        "komposition": komposition,
        "confidence": confidence,
        "processing_time": 0.5,
        "cost_usd": 0.03,
        "escalation_needed": confidence < confidence_threshold
    }

async def async_main(args):
    """Async main function to handle API calls"""
    try:
        print(f"ðŸŽµ Haiku Komposition Generator")
        print(f"Input: {args.input}")
        print(f"BPM: {args.bpm}")
        
        # Try real API first, fall back to simulation
        if API_AVAILABLE:
            print("ðŸ”— Connecting to Haiku API...")
            result = await call_haiku_llm_api(args.input, args.bpm, args.confidence_threshold)
        else:
            print("ðŸŽ­ Using simulation mode...")
            result = simulate_haiku_llm_call(args.input, args.bpm, args.confidence_threshold)
            
        return result
    except Exception as e:
        print(f"âŒ Error in async_main: {e}")
        return {"success": False, "error": str(e), "confidence": 0.0, "processing_time": 0.0, "cost_usd": 0.0, "escalation_needed": True}

def main():
    parser = argparse.ArgumentParser(description="Generate video komposition from natural language")
    parser.add_argument("--input", required=True, help="Natural language description")
    parser.add_argument("--bpm", type=int, default=120, help="BPM for timing calculations")
    parser.add_argument("--confidence-threshold", type=float, default=0.8, help="Minimum confidence score")
    parser.add_argument("--output", help="Output file path")
    parser.add_argument("--template", help="Template type (music_video, short_form, etc)")
    parser.add_argument("--api-mode", action="store_true", help="Force API mode (vs simulation)")
    parser.add_argument("--simulation-mode", action="store_true", help="Force simulation mode")
    
    args = parser.parse_args()
    
    try:
        # Override API availability based on arguments
        global API_AVAILABLE
        if args.simulation_mode:
            API_AVAILABLE = False
        elif args.api_mode and not API_AVAILABLE:
            print("âŒ API mode requested but API client not available")
            return 1
        
        # Run async main
        result = asyncio.run(async_main(args))
        
        # Handle escalation to Sonnet if needed
        if result["escalation_needed"] and SONNET_AVAILABLE:
            print(f"âš ï¸ Confidence {result['confidence']:.2f} below threshold {args.confidence_threshold}")
            print("ðŸ§  Escalating to Sonnet for validation...")
            
            try:
                # Create HaikuResponse object for validation
                from haiku_api_client import HaikuResponse
                haiku_response = HaikuResponse(
                    success=result["success"],
                    content=json.dumps(result["komposition"]),
                    confidence=result["confidence"],
                    cost_usd=result["cost_usd"],
                    processing_time=result["processing_time"],
                    escalation_needed=result["escalation_needed"]
                )
                
                validation = asyncio.run(validate_with_sonnet(haiku_response, args.input, args.bpm))
                
                if validation.validated and validation.improved_komposition:
                    print(f"âœ… Sonnet validation completed: {validation.confidence:.2f}")
                    print(f"ðŸ’¡ {validation.validation_notes}")
                    result["komposition"] = json.loads(validation.improved_komposition)
                    result["confidence"] = validation.confidence
                    result["cost_usd"] += validation.cost_usd
                    result["processing_time"] += validation.processing_time
                    result["escalation_needed"] = False
                else:
                    print(f"âŒ Sonnet validation failed: {validation.error or 'Low confidence'}")
                    if validation.validation_notes:
                        print(f"ðŸ“ Notes: {validation.validation_notes}")
            except Exception as e:
                print(f"âŒ Sonnet validation error: {e}")
                print("ðŸ§  Would escalate to Sonnet but API key not configured")
        elif result["escalation_needed"]:
            print(f"âš ï¸ Confidence {result['confidence']:.2f} below threshold {args.confidence_threshold}")
            print("ðŸ§  Would escalate to Sonnet but Sonnet validator not available")
        else:
            print(f"âœ… High confidence: {result['confidence']:.2f}")
        
        print(f"ðŸ’° Cost: ${result['cost_usd']:.3f}")
        print(f"âš¡ Processing time: {result['processing_time']:.1f}s")
        
        # Output results
        if args.output:
            with open(args.output, 'w') as f:
                json.dump(result["komposition"], f, indent=2)
            print(f"ðŸ“„ Komposition saved to: {args.output}")
        else:
            print("\nðŸ“‹ Generated Komposition:")
            print(json.dumps(result["komposition"], indent=2))
        
        # Return JSON with metadata for programmatic use
        output_data = {
            "komposition_file": args.output if args.output else "stdout",
            "confidence": result["confidence"],
            "cost": result["cost_usd"],
            "processing_time": result["processing_time"],
            "escalation_needed": result["escalation_needed"],
            "segments": len(result["komposition"]["segments"]),
            "estimated_duration": result["komposition"]["metadata"]["estimatedDuration"]
        }
        
        print(f"\nðŸ”§ CLI Result: {json.dumps(output_data)}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Error: {e}", file=sys.stderr)
        return 1

if __name__ == "__main__":
    sys.exit(main())