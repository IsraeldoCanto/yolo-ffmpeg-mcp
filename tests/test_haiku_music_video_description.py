#!/usr/bin/env python3
"""
Test Haiku MCP bridge by generating a description of our Subnautica music video
using the three YouTube shorts we've been working with.
"""
import asyncio
import json
import logging
import sys
import time
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Try to import the Haiku subagent
try:
    from haiku_subagent import HaikuSubagent, CostLimits
    HAIKU_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Haiku subagent not available: {e}")
    HAIKU_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_haiku_music_video_description():
    """Test Haiku bridge performance for generating music video descriptions"""
    
    if not HAIKU_AVAILABLE:
        print("âŒ Cannot test - Haiku subagent not available")
        return False
    
    print("ğŸ¬ Testing Haiku MCP Bridge: Music Video Description Generation")
    print("="*70)
    
    # Performance tracking
    start_time = time.time()
    performance_metrics = {
        "start_time": start_time,
        "stages": {}
    }
    
    # Initialize Haiku agent with cost controls
    cost_limits = CostLimits(daily_limit=5.0, per_analysis_limit=0.50)  # Higher limit for description generation
    
    stage_start = time.time()
    haiku_agent = HaikuSubagent(
        anthropic_api_key=None,  # Will test fallback first
        cost_limits=cost_limits,
        fallback_enabled=True
    )
    performance_metrics["stages"]["initialization"] = time.time() - stage_start
    
    print(f"âœ… Haiku agent initialized in {performance_metrics['stages']['initialization']:.2f}s")
    
    # Test video file information (our three shorts)
    video_info = {
        "videos": [
            {
                "id": "Oa8iS1W3OCM", 
                "file": "Oa8iS1W3OCM.mp4",
                "description": "Deep ocean underwater scenes with marine life and blue lighting",
                "duration": 60.0,
                "mood": "mysterious, deep, atmospheric"
            },
            {
                "id": "3xEMCU1fyl8", 
                "file": "3xEMCU1fyl8.mp4", 
                "description": "Ocean exploration and underwater adventure scenes",
                "duration": 60.1,
                "mood": "adventurous, exploratory, dynamic"
            },
            {
                "id": "PLnPZVqiyjA", 
                "file": "PLnPZVqiyjA.mp4",
                "description": "Subnautica game footage with underwater creatures and environments", 
                "duration": 107.4,
                "mood": "immersive, gaming, futuristic"
            }
        ],
        "audio": {
            "file": "Subnautic Measures.flac",
            "description": "Ambient electronic music with deep bass and atmospheric soundscape",
            "bpm": 120,
            "duration": 24.0
        },
        "target": {
            "duration": 24.0,
            "segments": 12,
            "theme": "Subnautica deep ocean exploration",
            "format": "YouTube Short (1080x1920, 24s)"
        }
    }
    
    # Test 1: Generate music video description using fallback (no API key)
    print("\nğŸ§  Test 1: Fallback Description Generation (No API)")
    stage_start = time.time()
    
    try:
        fallback_description = await generate_music_video_description_fallback(haiku_agent, video_info)
        performance_metrics["stages"]["fallback_generation"] = time.time() - stage_start
        
        print(f"âœ… Fallback generation completed in {performance_metrics['stages']['fallback_generation']:.2f}s")
        print(f"ğŸ“ Description length: {len(fallback_description)} characters")
        print(f"ğŸ“„ Preview: {fallback_description[:200]}...")
        
    except Exception as e:
        performance_metrics["stages"]["fallback_generation"] = time.time() - stage_start
        print(f"âŒ Fallback generation failed in {performance_metrics['stages']['fallback_generation']:.2f}s: {e}")
        fallback_description = None
    
    # Test 2: Try with API key if available
    import os
    api_key = os.getenv("ANTHROPIC_API_KEY")
    
    if api_key:
        print(f"\nğŸ§  Test 2: AI-Powered Description Generation (Haiku API)")
        
        # Reinitialize with API key
        stage_start = time.time()
        haiku_agent_ai = HaikuSubagent(
            anthropic_api_key=api_key,
            cost_limits=cost_limits,
            fallback_enabled=True
        )
        
        try:
            ai_description = await generate_music_video_description_ai(haiku_agent_ai, video_info)
            performance_metrics["stages"]["ai_generation"] = time.time() - stage_start
            
            print(f"âœ… AI generation completed in {performance_metrics['stages']['ai_generation']:.2f}s")
            print(f"ğŸ“ Description length: {len(ai_description)} characters")
            print(f"ğŸ“„ Preview: {ai_description[:200]}...")
            
            # Cost analysis
            cost_status = haiku_agent_ai.get_cost_status()
            print(f"ğŸ’° Cost: ${cost_status.get('daily_spend', 0):.4f} / ${cost_status.get('daily_limit', 0):.2f}")
            
        except Exception as e:
            performance_metrics["stages"]["ai_generation"] = time.time() - stage_start
            print(f"âŒ AI generation failed in {performance_metrics['stages']['ai_generation']:.2f}s: {e}")
            ai_description = None
    else:
        print("\nâš ï¸ Test 2 skipped: No ANTHROPIC_API_KEY found")
        ai_description = None
    
    # Performance analysis
    total_time = time.time() - start_time
    performance_metrics["total_time"] = total_time
    
    print(f"\nâ±ï¸ Performance Summary:")
    print(f"  Total time: {total_time:.2f}s")
    for stage, duration in performance_metrics["stages"].items():
        print(f"  {stage.replace('_', ' ').title()}: {duration:.2f}s")
    
    # Save results
    results = {
        "test_date": time.strftime("%Y-%m-%d %H:%M:%S"),
        "performance_metrics": performance_metrics,
        "video_info": video_info,
        "descriptions": {
            "fallback": fallback_description,
            "ai_powered": ai_description
        }
    }
    
    with open("haiku_music_video_test_results.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ“„ Results saved: haiku_music_video_test_results.json")
    return results

async def generate_music_video_description_fallback(haiku_agent, video_info):
    """Generate description using fallback heuristics (no API)"""
    
    # Use the fallback logic in HaikuSubagent
    videos = video_info["videos"]
    audio = video_info["audio"]
    target = video_info["target"]
    
    # Create a structured description using heuristics
    description = f"""ğŸ¬ SUBNAUTICA DEEP OCEAN MUSIC VIDEO

ğŸ¯ CONCEPT: {target['theme']}
â±ï¸ FORMAT: {target['format']}

ğŸ¥ VIDEO SOURCES:
"""
    
    for i, video in enumerate(videos, 1):
        segments_from_video = 4  # Each video contributes 4 segments
        segment_start = (i-1) * segments_from_video
        segment_end = segment_start + segments_from_video
        
        description += f"  {i}. {video['description']} ({video['duration']}s)\n"
        description += f"     â†’ Segments {segment_start+1:02d}-{segment_end:02d}: {video['mood']}\n"
    
    description += f"""
ğŸµ AUDIO: {audio['description']}
  â†’ BPM: {audio['bpm']}, Duration: {audio['duration']}s
  â†’ Sync: 12 segments Ã— 2s = 24s total

ğŸ¬ NARRATIVE STRUCTURE:
  Act 1 (0-8s): Deep ocean mystery and discovery
    - Segments from {videos[0]['id']}: {videos[0]['mood']}
    - Gradual descent into oceanic depths
  
  Act 2 (8-16s): Exploration and adventure  
    - Segments from {videos[1]['id']}: {videos[1]['mood']}
    - Dynamic movement through underwater landscapes
  
  Act 3 (16-24s): Immersive gaming experience
    - Segments from {videos[2]['id']}: {videos[2]['mood']}
    - Futuristic underwater world revelation

ğŸ¨ VISUAL EFFECTS:
  - Vignette effect for deep ocean atmosphere
  - Scale to 1080x1920 for vertical format
  - Unsharp filter for enhanced detail
  - Audio fade in/out for smooth transitions

âš¡ TECHNICAL: Content-aware segmentation with keyframe alignment
ğŸ’ QUALITY TARGET: Professional YouTube Short ready for upload"""
    
    return description

async def generate_music_video_description_ai(haiku_agent, video_info):
    """Generate description using AI analysis"""
    
    # Create video file list for analysis (simulated)
    video_files = [Path(v["file"]) for v in video_info["videos"]]
    
    try:
        # Use the actual analyze_video_files method
        analysis = await haiku_agent.analyze_video_files(video_files)
        
        # Generate description based on analysis results
        description = f"""ğŸ¬ SUBNAUTICA DEEP OCEAN MUSIC VIDEO (AI-GENERATED)

ğŸ¤– AI ANALYSIS RESULTS:
- Frame Issues Detected: {analysis.has_frame_issues}
- Normalization Needed: {analysis.needs_normalization}
- Complexity Score: {analysis.complexity_score:.2f}/1.0
- Recommended Strategy: {analysis.recommended_strategy.value}
- Confidence: {analysis.confidence:.2f}/1.0

ğŸ’¡ AI REASONING: {analysis.reasoning}

âš¡ PROCESSING RECOMMENDATION:
Using {analysis.recommended_strategy.value} approach based on AI analysis.
Estimated cost: ${analysis.estimated_cost:.4f}
Estimated time: {analysis.estimated_time:.1f}s

ğŸ¯ CREATIVE CONCEPT: {video_info['target']['theme']}
â±ï¸ FORMAT: {video_info['target']['format']}

ğŸ¥ VIDEO SOURCES (AI-OPTIMIZED):
"""
        
        for i, video in enumerate(video_info["videos"], 1):
            description += f"  {i}. {video['description']} ({video['duration']}s)\n"
            description += f"     â†’ Mood: {video['mood']}, Processing: {analysis.recommended_strategy.value}\n"
        
        description += f"""
ğŸµ AUDIO SYNC: {video_info['audio']['description']}
  â†’ BPM: {video_info['audio']['bpm']}, Segments: {video_info['target']['segments']}

ğŸ¬ AI-OPTIMIZED PRODUCTION NOTES:
  - Strategy: {analysis.recommended_strategy.value}
  - Quality Focus: {'High' if analysis.complexity_score > 0.7 else 'Standard'}
  - Frame Alignment: {'Required' if analysis.has_frame_issues else 'Standard'}
  - Normalization: {'Required' if analysis.needs_normalization else 'Not needed'}
  
ğŸ“Š CONFIDENCE LEVEL: {analysis.confidence * 100:.0f}%"""
        
        return description
        
    except Exception as e:
        logger.error(f"AI description generation failed: {e}")
        # Fallback to heuristic
        return await generate_music_video_description_fallback(haiku_agent, video_info)

async def analyze_haiku_bridge_performance(test_results):
    """Analyze the performance and identify improvements"""
    
    print("\nğŸ” HAIKU BRIDGE PERFORMANCE ANALYSIS")
    print("="*60)
    
    metrics = test_results["performance_metrics"]
    stages = metrics["stages"]
    
    # Performance analysis
    print("âš¡ Speed Analysis:")
    for stage, duration in stages.items():
        status = "âœ… Fast" if duration < 1.0 else "âš ï¸ Slow" if duration < 5.0 else "âŒ Very Slow"
        print(f"  {stage.replace('_', ' ').title()}: {duration:.2f}s {status}")
    
    print(f"\nğŸ“Š Total Processing: {metrics['total_time']:.2f}s")
    
    # Identify improvements
    improvements = []
    
    if stages.get("initialization", 0) > 1.0:
        improvements.append({
            "area": "Initialization",
            "issue": f"Takes {stages['initialization']:.2f}s to initialize",
            "solution": "Implement lazy loading and connection pooling"
        })
    
    if stages.get("fallback_generation", 0) > 2.0:
        improvements.append({
            "area": "Fallback Generation", 
            "issue": f"Heuristic generation takes {stages['fallback_generation']:.2f}s",
            "solution": "Pre-compute common templates and use caching"
        })
    
    if stages.get("ai_generation", 0) > 5.0:
        improvements.append({
            "area": "AI Generation",
            "issue": f"AI processing takes {stages['ai_generation']:.2f}s", 
            "solution": "Implement request batching and response streaming"
        })
    
    # Quality analysis
    descriptions = test_results["descriptions"]
    
    print(f"\nğŸ“ Quality Analysis:")
    if descriptions["fallback"]:
        fallback_len = len(descriptions["fallback"])
        print(f"  Fallback description: {fallback_len} chars")
        print(f"  Quality: {'âœ… Good' if fallback_len > 500 else 'âš ï¸ Basic'}")
    
    if descriptions["ai_powered"]:
        ai_len = len(descriptions["ai_powered"])
        print(f"  AI description: {ai_len} chars") 
        print(f"  Quality: {'âœ… Excellent' if ai_len > 800 else 'âœ… Good' if ai_len > 500 else 'âš ï¸ Basic'}")
    
    # Improvement recommendations
    if improvements:
        print(f"\nğŸ› ï¸ Recommended Improvements:")
        for i, improvement in enumerate(improvements, 1):
            print(f"  {i}. {improvement['area']}")
            print(f"     Issue: {improvement['issue']}")
            print(f"     Solution: {improvement['solution']}")
    else:
        print(f"\nâœ… Performance is optimal - no improvements needed!")
    
    return improvements

async def main():
    """Main test function"""
    
    try:
        # Test Haiku bridge for music video description
        test_results = await test_haiku_music_video_description()
        
        if test_results:
            # Analyze performance and identify improvements
            improvements = await analyze_haiku_bridge_performance(test_results)
            
            print(f"\nğŸ¯ HAIKU BRIDGE TEST COMPLETE")
            print(f"ğŸ“„ Results: haiku_music_video_test_results.json")
            print(f"ğŸ› ï¸ Improvements identified: {len(improvements)}")
            
            return True
        else:
            print(f"\nâŒ Haiku bridge test failed")
            return False
            
    except Exception as e:
        print(f"\nğŸ’¥ Test execution failed: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)